- Q:证明定理：设$$\alpha^{*}=\left(\alpha_{1}^{*}, \alpha_{2}^{*}, \cdots, \alpha_{l}^{*}\right)^{\mathrm{T}}$$是对偶最优化问题
- "$$\begin{array}{ll}
\underset{\alpha}{\min} & \frac{1}{2} \sum\limits_{i=1}^{N} \sum\limits_{j=1}^{N} \alpha_{i} \alpha_{j} y_{i} y_{j}\left(x_{i} \cdot x_{j}\right)-\sum\limits_{i=1}^{N} \alpha_{i} \\
\text { s.t. } & \sum\limits_{i=1}^{N} \alpha_{i} y_{i}=0 \\
& \alpha_{i} \geqslant 0, \quad i=1,2, \cdots, N
\end{array}$$"
- 的解，则存在下标$$j$$，使得$$\alpha_{j}^{*}>0$$，并可按下式求得原始最优化问题
- "$$\begin{array}{ll}
\underset{w, b}{\min} & \frac{1}{2}\|w\|^{2} \\
\text { s.t. } & y_{i}\left(w \cdot x_{i}+b\right)-1 \geqslant 0, \quad i=1,2, \cdots, N
\end{array}$$"
- 的解$$w^*,b^*$$:
- "$$w^{*}=\sum_{i=1}^{N} \alpha_{i}^{*} y_{i} x_{i}$$"
- $$b^{*}=y_{j}-\sum_{i=1}^{N} \alpha_{i}^{*} y_{i}\left(x_{i} \cdot x_{j}\right)$$
    - 根据定理，KKT条件成立，即得
    - $$\nabla_{w} L\left(w^{*}, b^{*}, \alpha^{*}\right)=w^{*}-\sum_{i=1}^{N} \alpha_{i}^{*} y_{i} x_{i}=0$$
    - "$$\nabla_{b} L\left(w^{*}, b^{*}, \alpha^{*}\right)=-\sum_{i=1}^{N} \alpha_{i}^{*} y_{i}=0$$"
    - $$\alpha_{i}^{*}\left(y_{i}\left(w^{*} \cdot x_{i}+b^{*}\right)-1\right)=0, \quad i=1,2, \cdots, N $$
    - $$y_{i}\left(w^{*} \cdot x_{i}+b^{*}\right)-1 \geqslant 0, \quad i=1,2, \cdots, N $$
    - $$\alpha_{i}^{*} \geqslant 0, \quad i=1,2, \cdots, N$$
    - 由此得
    - $$w^{*}=\sum\limits_{i} \alpha_{i}^{*} y_{i} x_{i}$$
    - 其中至少有一个$$\alpha_{j}^{*}>0$$(用反证法，假设$$\alpha^*=0$$，由式"$$\nabla_{w} L\left(w^{*}, b^{*}, \alpha^{*}\right)=w^{*}-\sum_{i=1}^{N} \alpha_{i}^{*} y_{i} x_{i}=0$$"可知$$w^*=0$$，而$$w^*=0$$不是原始最优化问题的解，产生矛盾)，对此j有
    - $$y_{j}\left(w^{*} \cdot x_{j}+b^{*}\right)-1=0$$
    - 将"$$w^{*}=\sum_{i=1}^{N} \alpha_{i}^{*} y_{i} x_{i}$$"代入上式，并有$$y_j^2 = 1$$，可得
    - $$b^{*}=y_{j}-\sum_{i=1}^{N} \alpha_{i}^{*} y_{i}\left(x_{i} \cdot x_{j}\right)$$
    - 注意在这个定理中，$$w^*$$和$$b^*$$值依赖于训练数据中对应于$$\alpha_{j}^{*}>0$$的样本点($$x_j,y_j$$)，而其它样本点对$$w^*$$和$$b^*$$没有影响，我们将训练数据中对应于$$\alpha_{j}^{*}>0$$的实例点$$x_{j} \in \mathbf{R}^{n}$$称为^^支持向量^^
